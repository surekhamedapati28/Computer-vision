{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"10UamWG_woeLIczlTwwrv6TvAOLpe1A0P","authorship_tag":"ABX9TyMbNPg60eYOnKp5PUGEqI44"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"LTqmPmYCWI3p","executionInfo":{"status":"ok","timestamp":1735257094493,"user_tz":-120,"elapsed":252,"user":{"displayName":"satti surekha","userId":"15322478345527838929"}}},"outputs":[],"source":[]},{"cell_type":"code","source":["import copy\n","import os\n","import random\n","import sys\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms\n","from torchvision import models\n","from tqdm import tqdm\n","from PIL import Image\n","from sklearn.metrics import cohen_kappa_score\n","from sklearn.ensemble import GradientBoostingClassifier\n","\n","# Modified Models\n","class BaseResNet(nn.Module):\n","    def __init__(self, model_name, num_classes=5):\n","        super(BaseResNet, self).__init__()\n","        if model_name == \"resnet18\":\n","            self.backbone = models.resnet18(pretrained=True)\n","        elif model_name == \"resnet34\":\n","            self.backbone = models.resnet34(pretrained=True)\n","        elif model_name == \"efficientnet\":\n","            self.backbone = models.efficientnet_b0(pretrained=True)\n","        else:\n","            raise ValueError(\"Unsupported model_name\")\n","\n","        if hasattr(self.backbone, 'fc'):\n","            self.backbone.fc = nn.Linear(self.backbone.fc.in_features, num_classes)\n","        else:\n","            self.backbone.classifier = nn.Linear(self.backbone.classifier[1].in_features, num_classes)\n","\n","    def forward(self, x):\n","        return self.backbone(x)\n","\n","# Dataset Class\n","class RetinopathyDataset(Dataset):\n","    def __init__(self, ann_file, image_dir, transform=None, test=False):\n","        self.ann_file = ann_file\n","        self.image_dir = image_dir\n","        self.transform = transform\n","        self.test = test\n","        self.data = self.load_data()\n","\n","    def load_data(self):\n","        df = pd.read_csv(self.ann_file)\n","        data = []\n","        for _, row in df.iterrows():\n","            file_info = {'img_path': os.path.join(self.image_dir, row['img_path'])}\n","            if not self.test:\n","                file_info['label'] = int(row['patient_DR_Level'])\n","            else:\n","                file_info['id'] = row['img_path']\n","            data.append(file_info)\n","        return data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.data[idx]['img_path']\n","        img = Image.open(img_path).convert('RGB')\n","        if self.transform:\n","            img = self.transform(img)\n","        if self.test:\n","            return img, os.path.basename(img_path)\n","        label = self.data[idx]['label']\n","        return img, label\n","\n","# Transforms\n","transform_train = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.RandomCrop((224, 224)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","# Data Loaders\n","def get_dataloaders(batch_size, train_ann, val_ann, test_ann, train_dir, val_dir, test_dir):\n","    train_dataset = RetinopathyDataset(train_ann, train_dir, transform_train)\n","    val_dataset = RetinopathyDataset(val_ann, val_dir, transform_test)\n","    test_dataset = RetinopathyDataset(test_ann, test_dir, transform_test, test=True)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n","\n","    return train_loader, val_loader, test_loader\n","\n","# Save Test Predictions\n","def save_test_predictions(predictions, ids, output_file=\"/content/drive/MyDrive/Colab Notebooks/dataset/boosting.csv\"):\n","    df = pd.DataFrame({\n","        \"ID\": ids,\n","        \"Target\": predictions\n","    })\n","    df.to_csv(output_file, index=False)\n","    print(f\"Test predictions saved to {output_file}\")\n","\n","# Visualization Function\n","def plot_metrics(train_losses, val_losses, train_accuracies, val_accuracies):\n","    epochs = range(1, len(train_losses) + 1)\n","\n","    # Loss Plot\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(epochs, train_losses, label='Training Loss')\n","    plt.plot(epochs, val_losses, label='Validation Loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.title('Loss Over Epochs')\n","    plt.legend()\n","    plt.show()\n","\n","    # Accuracy Plot\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(epochs, train_accuracies, label='Training Accuracy')\n","    plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.title('Accuracy Over Epochs')\n","    plt.legend()\n","    plt.show()\n","\n","# Main Function\n","if __name__ == \"__main__\":\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # Models\n","    resnet18 = BaseResNet(\"resnet18\", num_classes=5).to(device)\n","    resnet34 = BaseResNet(\"resnet34\", num_classes=5).to(device)\n","    efficientnet = BaseResNet(\"efficientnet\", num_classes=5).to(device)\n","\n","    # Hyperparameters\n","    batch_size = 32\n","    train_ann = \"/content/drive/MyDrive/Colab Notebooks/dataset/521153S-3005-final-project/DeepDRiD/train.csv\"\n","    val_ann = \"/content/drive/MyDrive/Colab Notebooks/dataset/521153S-3005-final-project/DeepDRiD/val.csv\"\n","    test_ann = \"/content/drive/MyDrive/Colab Notebooks/dataset/521153S-3005-final-project/DeepDRiD/test.csv\"\n","\n","    train_dir = \"/content/drive/MyDrive/Colab Notebooks/dataset/521153S-3005-final-project/DeepDRiD/train/\"\n","    val_dir = \"/content/drive/MyDrive/Colab Notebooks/dataset/521153S-3005-final-project/DeepDRiD/val/\"\n","    test_dir = \"/content/drive/MyDrive/Colab Notebooks/dataset/521153S-3005-final-project/DeepDRiD/test/\"\n","    train_loader, val_loader, test_loader = get_dataloaders(batch_size, train_ann, val_ann, test_ann, train_dir, val_dir, test_dir)\n","\n","    # Training Parameters\n","    train_data = []\n","    train_labels = []\n","    for imgs, labels in train_loader:\n","        train_data.extend(imgs.numpy())\n","        train_labels.extend(labels.numpy())\n","\n","    train_data = np.array(train_data)\n","    train_labels = np.array(train_labels)\n","\n","    # Flatten data for Gradient Boosting Classifier\n","    train_data_flat = train_data.reshape(train_data.shape[0], -1)\n","\n","    # Boosting\n","    gbc = GradientBoostingClassifier()\n","    print(\"Training Gradient Boosting Classifier...\")\n","    gbc.fit(train_data_flat, train_labels)\n","\n","    print(\"Boosting Completed.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k06ns47-aHqG","executionInfo":{"status":"ok","timestamp":1735279143638,"user_tz":-120,"elapsed":21504469,"user":{"displayName":"satti surekha","userId":"15322478345527838929"}},"outputId":"77c42be9-ac27-496e-93f3-0ce61b8a2780"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Training Gradient Boosting Classifier...\n","Boosting Completed.\n"]}]}]}